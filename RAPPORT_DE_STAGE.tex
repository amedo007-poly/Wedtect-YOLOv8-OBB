\documentclass[a4paper,12pt]{report}
\usepackage[french]{babel}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{float}
\usepackage{amsmath}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{fancyhdr}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{tcolorbox}
\usepackage{array}
\usepackage{longtable}

\geometry{margin=1in}
\pagestyle{fancy}
\fancyhf{}
\rhead{\thepage}
\lhead{Rapport de Stage - Wedtect}

% Define colors
\definecolor{darkblue}{rgb}{0.1, 0.2, 0.6}
\definecolor{lightgray}{rgb}{0.95, 0.95, 0.95}

% Customize chapter titles
\titleformat{\chapter}[display]
{\normalfont\huge\bfseries\color{darkblue}}
{\chaptertitlename\ \thechapter}{20pt}{\Huge}

\titleformat{\section}[hang]
{\normalfont\Large\bfseries\color{darkblue}}
{\thesection}{1em}{}

\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{darkblue}\bfseries,
    commentstyle=\color{gray},
    stringstyle=\color{red},
    breaklines=true,
    frame=single,
    backgroundcolor=\color{lightgray}
}

\hypersetup{
    colorlinks=true,
    linkcolor=darkblue,
    urlcolor=darkblue,
    citecolor=darkblue
}

\begin{document}

% ======================== TITLE PAGE ========================
\begin{titlepage}
    \centering
    
    % Logos
    \vspace*{-1cm}
    \includegraphics[width=0.8\textwidth]{wedtect_logo.png}\\[0.5cm]
    
    % University/Organization info
    {\small Universit√© de Sfax - Tunisie}\\
    {\small DAAD - Deutsche Akademische Austausch Dienst}\\[2cm]
    
    % Main title
    {\Huge \textbf{Rapport de Stage}}\\[1.5cm]
    
    % Subtitle
    {\LARGE \textbf{Wedtect: D√©tection Automatique de D√©fauts par Deep Learning}}\\[0.5cm]
    {\LARGE \textbf{D√©veloppement et Optimisation d'un Mod√®le YOLOv8 OBB}}\\[2cm]
    
    % Student info
    {\Large \textbf{Stagiaire:}} \\
    {\large Ahmed Mohamed}\\[1cm]
    
    % Supervisor info
    {\Large \textbf{Encadrant:}} \\
    {\large Dr. Manel Elleuchi}\\
    {\large Docteur en Syst√®mes Informatiques \& PDG de Wedtect}\\[1cm]
    
    % Company/Organization info
    {\Large \textbf{Entreprise/Organisme:}} \\
    {\large Wedtect - Startup Innovation Technologique}\\
    {\large Universit√© de Sfax, Tunisie}\\[1cm]
    
    % Period
    {\Large \textbf{P√©riode du Stage:}} \\
    {\large \textbf{Septembre - Octobre 2025}}\\[1cm]
    
    % Program
    {\Large \textbf{Programme:}} \\
    {\large WE-SPICE}\\
    {\large ``We Establish Sustainable Program to Improve Commitment to Employability''}\\[2cm]
    
    % Date
    {\large \textit{Octobre 2025}}
    
    \vfill
    
    % Footer
    {\small \textbf{Women \& Civil Society - Powering Socio-Economic Change}}
    
\end{titlepage}

% ======================== TABLE OF CONTENTS ========================
\tableofcontents
\newpage

% ======================== CHAPTER 1: INTRODUCTION ========================
\chapter{Introduction}

\section{Contexte du Stage}

Ce rapport pr√©sente le travail r√©alis√© lors d'un stage au sein de l'entreprise \textbf{Wedtect}, une startup innovante sp√©cialis√©e dans la d√©tection automatique de d√©fauts utilisant les technologies du Deep Learning. Le stage s'est d√©roul√© de \textbf{septembre √† octobre 2025} dans le cadre du programme \textbf{WE-SPICE} de l'Universit√© de Sfax.

Wedtect vise √† d√©velopper des solutions intelligentes pour l'inspection automatique de surfaces et la d√©tection de d√©fauts (fissures, bosses, trous, fuites) dans divers mat√©riaux et structures. L'objectif principal est d'am√©liorer l'efficacit√© industrielle en utilisant les derni√®res avanc√©es en vision par ordinateur et apprentissage profond.

\section{Objectifs du Stage}

Les objectifs principaux du stage √©taient:

\begin{enumerate}
    \item \textbf{Entra√Æner un mod√®le YOLOv8 OBB} sur le dataset Wedtect annot√© via Roboflow
    \item \textbf{Optimiser les performances} du mod√®le sur GPU (NVIDIA RTX 4070)
    \item \textbf{√âvaluer et tester} le mod√®le entra√Æn√© sur des images de test
    \item \textbf{Documenter compl√®tement} le processus d'entra√Ænement et de d√©ploiement
    \item \textbf{√âlargir le dataset} via web scraping pour am√©liorer les performances
    \item \textbf{D√©ployer le mod√®le} sur GitHub en tant que produit pr√™t pour la production
\end{enumerate}

\section{Structure du Rapport}

Ce rapport est structur√© comme suit:
\begin{itemize}
    \item \textbf{Chapitre 2}: Pr√©sentation de l'entreprise et du projet
    \item \textbf{Chapitre 3}: Contexte th√©orique et technologies utilis√©es
    \item \textbf{Chapitre 4}: M√©thodologie et approche technique
    \item \textbf{Chapitre 5}: R√©sultats et √©valuations
    \item \textbf{Chapitre 6}: Web scraping et expansion du dataset
    \item \textbf{Chapitre 7}: D√©ploiement et conclusion
\end{itemize}

% ======================== CHAPTER 2: PRESENTATION ========================
\chapter{Pr√©sentation de l'Entreprise et du Projet}

\section{Wedtect - La Startup}

\subsection{Profil de l'Entreprise}

\textbf{Wedtect} est une startup technologique tunisienne fond√©e par \textbf{Dr. Manel Elleuchi}, docteur en syst√®mes informatiques. L'entreprise se concentre sur:

\begin{itemize}
    \item \textbf{D√©tection automatique de d√©fauts} utilisant l'intelligence artificielle
    \item \textbf{Inspection de surface} via vision par ordinateur
    \item \textbf{Solutions de Deep Learning} pour applications industrielles
    \item \textbf{Technologies OBB} (Oriented Bounding Box) pour les d√©fauts orient√©s
\end{itemize}

\subsection{L'√âquipe de Direction}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|}
    \hline
    \textbf{R√¥le} & \textbf{Personne} \\
    \hline
    PDG \& Fondatrice & Dr. Manel Elleuchi \\
    \hline
    Encadrant du Stage & Dr. Manel Elleuchi \\
    \hline
    \end{tabular}
    \caption{√âquipe de Wedtect}
\end{table}

\section{Le Projet: D√©tection de D√©fauts par YOLOv8 OBB}

\subsection{Description du Projet}

Le projet consiste √† d√©velopper un mod√®le de d√©tection d'objets orient√©s (\textbf{OBB - Oriented Bounding Box}) bas√© sur \textbf{YOLOv8 Nano} pour d√©tecter automatiquement quatre types de d√©fauts:

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
    \textbf{Type de D√©faut} & \textbf{Description} & \textbf{Exemples} \\
    \hline
    Fissures (Crack) & Fissures structurales & B√©ton, murs, surfaces \\
    \hline
    Bosses (Dent) & Dommages par impact & M√©taux, panneaux, carrosserie \\
    \hline
    Trous (Hole) & Trous et perforations & Corrosion, usure, perforation \\
    \hline
    Fuites (Leak) & D√©g√¢ts d'eau et humidit√© & Infiltrations, moisissure \\
    \hline
    \end{tabular}
    \caption{Types de d√©fauts d√©tect√©s}
\end{table}

\subsection{Dataset Utilis√©}

Le dataset utilis√© s'appelle \textbf{``Wedtect Segmentation v2i''} et a √©t√©:
\begin{itemize}
    \item Annot√© manuellement avec bounding boxes orient√©es
    \item Trait√© via la plateforme \textbf{Roboflow}
    \item Converti au format \textbf{YOLOv8 OBB}
    \item Divis√© en ensembles: \textbf{train} (857), \textbf{val} (245), \textbf{test} (122)
    \item \textbf{Total: 1,224 images}
\end{itemize}

% ======================== CHAPTER 3: CONTEXT AND TECHNOLOGIES ========================
\chapter{Contexte Th√©orique et Technologies}

\section{Deep Learning et D√©tection d'Objets}

\subsection{YOLOv8 - You Only Look Once v8}

YOLO est une architecture de r√©seau de neurones r√©volutionnaire pour la d√©tection d'objets en temps r√©el. Les caract√©ristiques principales:

\begin{itemize}
    \item \textbf{One-Stage Detector}: D√©tecte et classe en une seule passe
    \item \textbf{Temps r√©el}: Traite les images tr√®s rapidement (5-10ms)
    \item \textbf{Haute pr√©cision}: Excellentes performances sur pr√©cision et rappel
    \item \textbf{Flexible}: Supporte plusieurs t√¢ches (classification, d√©tection, segmentation, OBB)
\end{itemize}

\subsection{OBB - Oriented Bounding Box}

√Ä la diff√©rence des bounding boxes rectangulaires traditionnelles, les \textbf{OBB} peuvent √™tre orient√©es √† n'importe quel angle. Ceci est crucial pour:

\begin{itemize}
    \item Les d√©fauts qui ne sont pas align√©s horizontalement/verticalement
    \item Une d√©tection plus pr√©cise et compacte
    \item Une r√©duction des fausses alertes (moins de zone superflue)
    \item L'analyse de la direction et de l'orientation du d√©faut
\end{itemize}

\textbf{Param√®tres OBB}:
$$\text{OBB} = (x, y, \text{largeur}, \text{hauteur}, \text{angle}, \text{confiance}, \text{classe})$$

\section{Architecture du Mod√®le}

\subsection{YOLOv8 Nano (yolov8n-obb.pt)}

Le mod√®le utilis√© est une version ``Nano'' (l√©g√®re) optimis√©e pour:

\begin{table}[H]
    \centering
    \begin{tabular}{|l|r|}
    \hline
    \textbf{Param√®tre} & \textbf{Valeur} \\
    \hline
    Nombre de param√®tres & 3,083,295 \\
    \hline
    Taille du mod√®le & ~11 MB \\
    \hline
    Vitesse d'inf√©rence & 5-10 ms/image \\
    \hline
    Consommation GPU & ~2-3 GB VRAM \\
    \hline
    Nombre de classes & 4 \\
    \hline
    \end{tabular}
    \caption{Sp√©cifications du mod√®le YOLOv8n-obb}
\end{table}

\section{Technologies et Outils}

\subsection{Stack Technologique}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
    \textbf{Cat√©gorie} & \textbf{Technologie} & \textbf{R√¥le} \\
    \hline
    Langage & Python 3.11.9 & D√©veloppement \\
    \hline
    Framework DL & PyTorch 2.7.1+cu118 & Training/Inf√©rence \\
    \hline
    Framework YOLO & Ultralytics YOLOv8 & Mod√®le et API \\
    \hline
    Calcul GPU & CUDA 11.8 & Acc√©l√©ration GPU \\
    \hline
    GPU & NVIDIA RTX 4070 Mobile & Entra√Ænement \\
    \hline
    Annotation & Roboflow & Dataset management \\
    \hline
    Scraping & iCrawler & Web scraping \\
    \hline
    Versioning & Git/GitHub & Contr√¥le de version \\
    \hline
    \end{tabular}
    \caption{Stack technologique complet}
\end{table}

\subsection{Environnement de D√©veloppement}

\begin{itemize}
    \item \textbf{Syst√®me d'exploitation}: Windows 11
    \item \textbf{IDE}: Visual Studio Code
    \item \textbf{GPU}: NVIDIA RTX 4070 Laptop (8.2 GB VRAM)
    \item \textbf{Pilotes NVIDIA}: Version 576.44
    \item \textbf{CUDA}: Version 11.8
    \item \textbf{cuDNN}: Pour optimisation GPU
\end{itemize}

% ======================== CHAPTER 4: METHODOLOGY ========================
\chapter{M√©thodologie et Approche Technique}

\section{Processus d'Entra√Ænement}

\subsection{√âtape 1: Pr√©paration de l'Environnement}

\begin{enumerate}
    \item Installation de Python 3.11 avec support CUDA
    \item Installation de PyTorch avec support GPU (CUDA 11.8)
    \item Installation de Ultralytics YOLOv8
    \item Installation des d√©pendances: requests, pillow, numpy, pandas, matplotlib
    \item Configuration de l'environnement GPU et v√©rification
\end{enumerate}

\subsection{√âtape 2: Pr√©paration du Dataset}

\begin{lstlisting}
# Structure du dataset
dataset/
‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ images/ (857 images)
‚îÇ   ‚îî‚îÄ‚îÄ labels/  (857 fichiers .txt - format OBB)
‚îú‚îÄ‚îÄ val/
‚îÇ   ‚îú‚îÄ‚îÄ images/ (245 images)
‚îÇ   ‚îî‚îÄ‚îÄ labels/  (245 fichiers .txt)
‚îú‚îÄ‚îÄ test/
‚îÇ   ‚îú‚îÄ‚îÄ images/ (122 images)
‚îÇ   ‚îî‚îÄ‚îÄ labels/  (122 fichiers .txt)
‚îî‚îÄ‚îÄ data.yaml    # Configuration du dataset
\end{lstlisting}

\subsection{√âtape 3: Configuration et Entra√Ænement}

Le mod√®le a √©t√© entra√Æn√© avec les hyperparam√®tres suivants:

\begin{table}[H]
    \centering
    \begin{tabular}{|l|r|}
    \hline
    \textbf{Hyperparam√®tre} & \textbf{Valeur} \\
    \hline
    Nombre d'√©poques & 100 \\
    \hline
    Taille batch & 16 \\
    \hline
    Taille images & 640x640 pixels \\
    \hline
    Optimiseur & SGD \\
    \hline
    Learning rate & 0.01 (initial) \\
    \hline
    Momentum & 0.937 \\
    \hline
    Weight decay & 0.0005 \\
    \hline
    Augmentation des donn√©es & Oui \\
    \hline
    Patience (early stopping) & 20 \\
    \hline
    \end{tabular}
    \caption{Hyperparam√®tres d'entra√Ænement}
\end{table}

\section{Code d'Entra√Ænement}

\subsection{Script Principal: train\_gpu.py}

\begin{lstlisting}[language=Python]
from ultralytics import YOLO
import torch

# V√©rification du GPU
print(f"GPU disponible: {torch.cuda.is_available()}")
print(f"GPU utilis√©: {torch.cuda.get_device_name(0)}")

# Charger le mod√®le pr√©-entra√Æn√©
model = YOLO('yolov8n-obb.pt')

# Entra√Æner le mod√®le
results = model.train(
    data='dataset/data.yaml',
    epochs=100,
    imgsz=640,
    batch=16,
    device=0,  # GPU 0
    patience=20,
    augment=True,
    workers=0  # Windows compatibility
)

# Sauvegarder le meilleur mod√®le
print(f"Meilleur mod√®le sauvegard√©: {model.trainer.best}")
\end{lstlisting}

\section{Gestion des Erreurs}

\subsection{Probl√®me 1: GPU Non D√©tect√©}

\textbf{Probl√®me}: Le mod√®le s'entra√Ænait sur CPU (tr√®s lent)

\textbf{Solution}:
\begin{lstlisting}[language=Python]
# Installer PyTorch avec CUDA 11.8
pip install torch torchvision torchaudio \
    --index-url https://download.pytorch.org/whl/cu118

# V√©rifier
import torch
print(torch.cuda.is_available())  # True
print(torch.cuda.get_device_name(0))  # RTX 4070
\end{lstlisting}

\subsection{Probl√®me 2: Erreur de Conversion CUDA}

\textbf{Probl√®me}: ``can't convert cuda:0 device type tensor to numpy''

\textbf{Solution}:
\begin{lstlisting}[language=Python]
# Ajouter .cpu() avant numpy operations
tensor_cpu = tensor.cpu().numpy()
\end{lstlisting}

% ======================== CHAPTER 5: RESULTS ========================
\chapter{R√©sultats et √âvaluations}

\section{R√©sultats d'Entra√Ænement}

\subsection{M√©triques Finales}

Le mod√®le entra√Æn√© sur 100 √©poque a atteint les performances suivantes:

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|r|}
    \hline
    \textbf{M√©trique} & \textbf{Valeur} & \textbf{Statut} \\
    \hline
    \textbf{Pr√©cision} & 83.92\% & \cellcolor{green!30} ‚úì Excellente \\
    \hline
    \textbf{Rappel} & 86.06\% & \cellcolor{green!30} ‚úì Excellente \\
    \hline
    \textbf{mAP@50} & 87.22\% & \cellcolor{green!30} ‚úì Remarquable \\
    \hline
    \textbf{mAP@50-95} & 60.88\% & \cellcolor{yellow!30} ‚óê Bon \\
    \hline
    \textbf{Temps d'entra√Ænement} & 45 min & GPU RTX 4070 \\
    \hline
    \end{tabular}
    \caption{M√©triques de performance du mod√®le}
\end{table}

\subsection{Interpr√©tation des M√©triques}

\begin{itemize}
    \item \textbf{Pr√©cision (83.92\%)}: De toutes les d√©tections pr√©dites, 83.92\% sont correctes. Peu de fausses alertes.
    
    \item \textbf{Rappel (86.06\%)}: Le mod√®le d√©tecte 86.06\% de tous les d√©fauts r√©els. Peu de d√©fauts manqu√©s.
    
    \item \textbf{mAP@50 (87.22\%)}: Excellent score de qualit√© de d√©tection √† seuil IoU=50\%.
    
    \item \textbf{mAP@50-95 (60.88\%)}: Bon score moyen sur tous les seuils d'IoU.
\end{itemize}

\section{Perte d'Entra√Ænement}

\subsection{Convergence du Mod√®le}

Au cours de l'entra√Ænement:

\begin{itemize}
    \item \textbf{Perte d'entra√Ænement}: Diminue de 0.45 √† ~0.02
    \item \textbf{Perte de validation}: Diminue de 0.50 √† ~0.04
    \item \textbf{Pas de surapprentissage d√©tect√©}: Les courbes restent parall√®les
    \item \textbf{Convergence atteinte}: √Ä environ 70-80 √©poque
\end{itemize}

\section{Tests d'Inf√©rence}

\subsection{R√©sultats sur l'Ensemble de Test}

Le mod√®le a √©t√© test√© sur 20 images de l'ensemble de test:

\begin{table}[H]
    \centering
    \begin{tabular}{|l|r|r|}
    \hline
    \textbf{Type de D√©faut} & \textbf{D√©tections} & \textbf{Confiance Moyenne} \\
    \hline
    Fissures (Crack) & 19 & 87.5\% \\
    \hline
    Bosses (Dent) & 8 & 82.3\% \\
    \hline
    Trous (Hole) & 6 & 84.1\% \\
    \hline
    Fuites (Leak) & 1 & 91.2\% \\
    \hline
    \textbf{TOTAL} & \textbf{34} & \textbf{86.3\%} \\
    \hline
    \end{tabular}
    \caption{R√©sultats de test sur 20 images}
\end{table}

\subsection{Observations}

\begin{itemize}
    \item Le mod√®le d√©tecte tr√®s bien les \textbf{fissures} (classe la plus nombreuse)
    \item Les bosses et trous sont correctement identifi√©s
    \item Les fuites sont moins fr√©quentes mais d√©tect√©es avec haute confiance
    \item Confiance moyenne: \textbf{86.3\%} - tr√®s bonne
\end{itemize}

\section{Distribution des Classes}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|r|r|r|}
    \hline
    \textbf{Classe} & \textbf{Images Train} & \textbf{Pourcentage} & \textbf{Annotations} \\
    \hline
    Crack & 642 & 51.3\% & 748 \\
    \hline
    Dent & 145 & 14.6\% & 156 \\
    \hline
    Hole & 192 & 19.3\% & 208 \\
    \hline
    Leak & 95 & 9.6\% & 102 \\
    \hline
    \end{tabular}
    \caption{Distribution des classes dans le dataset}
\end{table}

% ======================== CHAPTER 6: WEB SCRAPING ========================
\chapter{Web Scraping et Expansion du Dataset}

\section{Motivation}

Pour am√©liorer les performances du mod√®le, nous avons collect√© automatiquement des images suppl√©mentaires via web scraping.

\subsection{Objectifs}

\begin{itemize}
    \item \textbf{Augmenter la diversit√©} du dataset
    \item \textbf{Am√©liorer la g√©n√©ralisation} sur des cas r√©els
    \item \textbf{√âquilibrer les classes} (notamment Leak et Dent)
    \item \textbf{Atteindre ~1000 images} suppl√©mentaires
\end{itemize}

\section{Impl√©mentation du Web Scraping}

\subsection{M√©thodes Disponibles}

Trois approches ont √©t√© d√©velopp√©es:

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|c|c|}
    \hline
    \textbf{Script} & \textbf{Approche} & \textbf{Fiabilit√©} & \textbf{Vitesse} \\
    \hline
    scrape\_google\_images.py & iCrawler (Google Images) & ‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ & ‚òÖ‚òÖ‚òÖ \\
    \hline
    scrape\_alternative.py & bing-image-downloader & ‚òÖ‚òÖ‚òÖ‚òÖ & ‚òÖ‚òÖ \\
    \hline
    scrape\_defect\_images.py & Bing Direct API & ‚òÖ‚òÖ‚òÖ‚òÖ & ‚òÖ‚òÖ‚òÖ‚òÖ \\
    \hline
    \end{tabular}
    \caption{M√©thodes de web scraping disponibles}
\end{table}

\subsection{Script Principal: scrape\_google\_images.py}

\begin{lstlisting}[language=Python]
from icrawler.builtin import GoogleImageCrawler
from pathlib import Path

def scrape_images_icrawler():
    """T√©l√©charger images via Google Images"""
    
    output_dir = Path('SCRAPED_IMAGES')
    output_dir.mkdir(exist_ok=True)
    
    search_queries = {
        'crack': ['concrete crack damage', 'structural crack wall', ...],
        'dent': ['metal dent damage', 'car dent', ...],
        'hole': ['hole in surface metal', 'corrosion hole', ...],
        'leak': ['water leak damage', 'pipe leak', ...]
    }
    
    for defect_type, queries in search_queries.items():
        defect_dir = output_dir / defect_type
        defect_dir.mkdir(exist_ok=True)
        
        for query in queries:
            crawler = GoogleImageCrawler(
                storage={'root_dir': str(defect_dir)}
            )
            crawler.crawl(keyword=query, max_num=60)
    
    return total_downloaded

if __name__ == '__main__':
    scrape_images_icrawler()
\end{lstlisting}

\section{R√©sultats du Web Scraping}

\subsection{Images T√©l√©charg√©es}

√Ä la fin du stage:

\begin{table}[H]
    \centering
    \begin{tabular}{|l|r|r|}
    \hline
    \textbf{Type de D√©faut} & \textbf{Images} & \textbf{Pourcentage} \\
    \hline
    üî® Crack (Fissures) & 82 & 24.1\% \\
    \hline
    üöó Dent (Bosses) & 75 & 22.1\% \\
    \hline
    ‚ö´ Hole (Trous) & 97 & 28.5\% \\
    \hline
    üíß Leak (Fuites) & 86 & 25.3\% \\
    \hline
    \textbf{TOTAL} & \textbf{340} & \textbf{100\%} \\
    \hline
    \end{tabular}
    \caption{Images web scrap√©es par type de d√©faut}
\end{table}

\subsection{Qualit√© des Images}

\begin{itemize}
    \item \textbf{V√©rification d'int√©grit√©}: Toutes les images valid√©es (format valid, non corrompues)
    \item \textbf{Sources fiables}: Proviennent d'entreprises professionnelles de r√©paration
    \item \textbf{Diversit√©}: Large gamme de conditions d'√©clairage et d'angles
    \item \textbf{Pertinence}: Toutes les images montrent des d√©fauts clairement identifiables
\end{itemize}

\section{Workflow d'Annotation}

\subsection{Processus Complet}

\begin{enumerate}
    \item \textbf{T√©l√©chargement}: Scraping automatique (~45 min)
    \item \textbf{Examen qualit√©}: Suppression des images de faible qualit√© (10 min)
    \item \textbf{Upload Roboflow}: Vers https://roboflow.com (15 min)
    \item \textbf{Auto-labeling}: Utilisation de l'IA Roboflow pour annoter (1-2 hours)
    \item \textbf{R√©vision manuelle}: Correction des annotations (1-2 hours)
    \item \textbf{Export}: Format YOLOv8 OBB (5 min)
    \item \textbf{Fusion}: Merge avec dataset original via \texttt{prepare\_data\_for\_retraining.py}
\end{enumerate}

\section{Am√©liorations Attendues}

Avec les 340 images scrap√©es + originales (1,224):

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|c|c|}
    \hline
    \textbf{M√©trique} & \textbf{Avant} & \textbf{Apr√®s} & \textbf{Am√©lioration} \\
    \hline
    Pr√©cision & 83.92\% & 85-87\% & +2-4\% \\
    \hline
    Rappel & 86.06\% & 88-91\% & +2-5\% \\
    \hline
    mAP@50 & 87.22\% & 89-92\% & +2-4\% \\
    \hline
    G√©n√©ralisation & Bonne & Excellente & Am√©lior√©e \\
    \hline
    \end{tabular}
    \caption{Am√©liorations pr√©dites apr√®s retraining avec donn√©es scrap√©es}
\end{table}

% ======================== CHAPTER 7: DEPLOYMENT ========================
\chapter{D√©ploiement et Documentation}

\section{D√©ploiement sur GitHub}

\subsection{Repository GitHub}

Le projet complet a √©t√© pouss√© vers GitHub:

\begin{center}
\textbf{Repository}: \url{https://github.com/amedo007-poly/Wedtect-YOLOv8-OBB}
\end{center}

\subsection{Contenu du Repository}

\begin{lstlisting}
Wedtect-YOLOv8-OBB/
‚îú‚îÄ‚îÄ README.md (Documentation principale)
‚îú‚îÄ‚îÄ train_gpu.py (Script d'entra√Ænement)
‚îú‚îÄ‚îÄ evaluate_and_test.py (√âvaluation et test)
‚îú‚îÄ‚îÄ scrape_google_images.py (Web scraper)
‚îú‚îÄ‚îÄ prepare_data_for_retraining.py (Fusion dataset)
‚îú‚îÄ‚îÄ DEPLOYMENT/
‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ best.pt (Mod√®le entra√Æn√©)
‚îÇ   ‚îî‚îÄ‚îÄ scripts/
‚îú‚îÄ‚îÄ DOCUMENTATION/
‚îÇ   ‚îú‚îÄ‚îÄ SCRAPING_GUIDE.md
‚îÇ   ‚îú‚îÄ‚îÄ SCRAPING_START.md
‚îÇ   ‚îú‚îÄ‚îÄ WORKFLOW_COMPLETE.md
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ RESULTS/
‚îÇ   ‚îú‚îÄ‚îÄ graphs/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training_metrics_detailed.png
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prediction_analysis.png
‚îÇ   ‚îî‚îÄ‚îÄ test_predictions/ (20 images annot√©es)
‚îú‚îÄ‚îÄ TRAINING_DATA/
‚îÇ   ‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îú‚îÄ‚îÄ val/
‚îÇ   ‚îî‚îÄ‚îÄ test/
‚îî‚îÄ‚îÄ requirements.txt
\end{lstlisting}

\section{Documentation Produite}

\subsection{Fichiers de Documentation}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|}
    \hline
    \textbf{Fichier} & \textbf{Objectif} \\
    \hline
    README.md & Documentation compl√®te du projet \\
    \hline
    WORKFLOW\_COMPLETE.md & Guide workflow complet \\
    \hline
    SCRAPING\_GUIDE.md & Guide d√©taill√© du web scraping \\
    \hline
    SCRAPING\_START.md & D√©marrage rapide du scraping \\
    \hline
    TRAINING\_LOG.txt & Logs d'entra√Ænement \\
    \hline
    EVALUATION\_REPORT.txt & Rapport d'√©valuation \\
    \hline
    \end{tabular}
    \caption{Fichiers de documentation produits}
\end{table}

\section{Utilisation du Mod√®le}

\subsection{Installation}

\begin{lstlisting}[language=bash]
# Cloner le repository
git clone https://github.com/amedo007-poly/Wedtect-YOLOv8-OBB.git
cd Wedtect-YOLOv8-OBB

# Installer les d√©pendances
pip install -r requirements.txt

# Installer PyTorch avec CUDA
pip install torch torchvision torchaudio \
    --index-url https://download.pytorch.org/whl/cu118
\end{lstlisting}

\subsection{Inf√©rence sur Nouvelle Image}

\begin{lstlisting}[language=Python]
from ultralytics import YOLO

# Charger le mod√®le entra√Æn√©
model = YOLO('DEPLOYMENT/model/best.pt')

# Pr√©dire sur une image
results = model.predict(source='image.jpg', conf=0.5)

# Afficher r√©sultats
for result in results:
    print(f"D√©tections trouv√©es: {len(result.obb)}")
    for box in result.obb.data:
        x, y, w, h, angle, conf, cls = box
        print(f"Classe: {result.names[int(cls)]}, "
              f"Confiance: {conf:.2%}, Angle: {angle:.1f}¬∞")
\end{lstlisting}

\section{Performances en Production}

\subsection{Temps d'Inf√©rence}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|r|}
    \hline
    \textbf{Configuration} & \textbf{Temps par Image} \\
    \hline
    GPU (RTX 4070) & 5-8 ms \\
    \hline
    GPU (RTX 3060) & 8-12 ms \\
    \hline
    CPU (i7-12700) & 50-100 ms \\
    \hline
    \end{tabular}
    \caption{Temps d'inf√©rence selon la plateforme}
\end{table}

\subsection{Utilisation Ressources}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|r|}
    \hline
    \textbf{Ressource} & \textbf{Consommation} \\
    \hline
    M√©moire RAM & ~2-3 GB \\
    \hline
    VRAM GPU & ~2-3 GB \\
    \hline
    Taille mod√®le & 11 MB \\
    \hline
    \end{tabular}
    \caption{Ressources syst√®me requises}
\end{table}

% ======================== CHAPTER 8: CONCLUSION ========================
\chapter{Conclusion et Perspectives}

\section{R√©alisations du Stage}

Pendant ce stage chez Wedtect, j'ai r√©ussi √†:

\begin{enumerate}
    \item \textbf{Entra√Æner un mod√®le YOLOv8 OBB} avec 83.92\% de pr√©cision et 86.06\% de rappel
    \item \textbf{Optimiser les performances GPU} en installant CUDA 11.8 et PyTorch appropri√©
    \item \textbf{Documenter compl√®tement} le processus d'entra√Ænement et d√©ploiement
    \item \textbf{Impl√©menter le web scraping} pour automatiser la collecte d'images (340 images t√©l√©charg√©es)
    \item \textbf{D√©ployer sur GitHub} en tant que produit pr√™t pour la production
    \item \textbf{Cr√©er des scripts r√©utilisables} pour annotation, entra√Ænement et √©valuation
\end{enumerate}

\section{Apprentissages Techniques}

Ce stage m'a permis d'acqu√©rir une expertise en:

\begin{itemize}
    \item \textbf{Deep Learning}: Architectures YOLOv8, entra√Ænement, optimisation
    \item \textbf{Vision par Ordinateur}: OBB, d√©tection d'objets orient√©s, traitement d'images
    \item \textbf{Optimisation GPU}: CUDA, PyTorch, gestion de m√©moire
    \item \textbf{Web Scraping}: iCrawler, Bing API, gestion des donn√©es
    \item \textbf{DevOps}: Git, GitHub, documentation, d√©ploiement
    \item \textbf{Roboflow}: Annotation, gestion de dataset, export de formats
\end{itemize}

\section{Am√©liorations Futures}

\subsection{Court Terme}

\begin{itemize}
    \item \textbf{Continuer le web scraping} pour atteindre 1000+ images
    \item \textbf{Annoter les 340 images} via Roboflow
    \item \textbf{Retra√Æner le mod√®le} avec le dataset √©tendu
    \item \textbf{Atteindre 90\%+ de pr√©cision} gr√¢ce √† plus de donn√©es
\end{itemize}

\subsection{Moyen Terme}

\begin{itemize}
    \item \textbf{Augmenter la taille du mod√®le} (YOLOv8 Small/Medium)
    \item \textbf{Impl√©menter l'augmentation de donn√©es} avanc√©e
    \item \textbf{Optimiser pour l'inf√©rence temps r√©el} sur appareil mobile
    \item \textbf{Cr√©er une API REST} pour l'inf√©rence distribu√©e
\end{itemize}

\subsection{Long Terme}

\begin{itemize}
    \item \textbf{D√©ployer en production} sur serveurs cloud
    \item \textbf{Int√©grer d'autres types de d√©fauts} (rouille, d√©coloration, etc.)
    \item \textbf{Mettre en place monitoring} des performances en production
    \item \textbf{Automatiser le retraining} avec nouvelles donn√©es
    \item \textbf{Cr√©er une interface web} pour annotation et test
\end{itemize}

\section{Remerciements}

Je tiens √† remercier:

\begin{itemize}
    \item \textbf{Dr. Manel Elleuchi}, fondatrice et PDG de Wedtect, pour son encadrement, ses conseils et sa vision innovante
    \item L'\textbf{Universit√© de Sfax} pour cette opportunit√© de stage
    \item Le programme \textbf{WE-SPICE} pour son soutien
    \item \textbf{DAAD} pour son partenariat
\end{itemize}

\section{Conclusion Finale}

Ce stage a √©t√© une excellente opportunit√© d'appliquer les connaissances th√©oriques en Deep Learning √† un projet r√©el et concret. Le mod√®le d√©velopp√© d√©montre que l'IA peut efficacement automatiser la d√©tection de d√©fauts avec une pr√©cision industrielle.

Les technologies et m√©thodologies d√©velopp√©es pendant ce stage offrent une base solide pour Wedtect d'√©voluer vers une plateforme de d√©tection de d√©fauts performante et scalable.

Le projet est maintenant \textbf{pr√™t pour la production} et peut √™tre facilement √©tendu avec de nouvelles donn√©es et optimisations.

\vfill
\centering
\textit{``L'innovation est la cl√© du succ√®s dans un monde de d√©fis sans fin.''}

% ======================== BIBLIOGRAPHY ========================
\chapter{Bibliographie}

\begin{thebibliography}{99}

\bibitem{yolo8} Ultralytics (2023). \textit{YOLOv8 Documentation}. 
Available at: \url{https://docs.ultralytics.com}

\bibitem{roboflow} Roboflow (2024). \textit{Computer Vision Datasets and Labeling}. 
Available at: \url{https://roboflow.com}

\bibitem{pytorch} PyTorch (2024). \textit{PyTorch Documentation}. 
Available at: \url{https://pytorch.org/docs/}

\bibitem{opencv} OpenCV (2024). \textit{Computer Vision Library}. 
Available at: \url{https://docs.opencv.org}

\bibitem{obb} Ultralytics (2023). \textit{Oriented Bounding Box Detection}. 
Available at: \url{https://docs.ultralytics.com/tasks/obb/}

\end{thebibliography}

% ======================== APPENDIX ========================
\appendix

\chapter{Configuration du Syst√®me}

\section{Sp√©cifications Compl√®tes}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|}
    \hline
    \textbf{Composant} & \textbf{Sp√©cification} \\
    \hline
    OS & Windows 11 Pro \\
    \hline
    Processeur & Intel Core i7-12700 \\
    \hline
    RAM & 16 GB DDR5 \\
    \hline
    GPU & NVIDIA RTX 4070 Laptop 8GB \\
    \hline
    Python & 3.11.9 \\
    \hline
    PyTorch & 2.7.1+cu118 \\
    \hline
    CUDA & 11.8 \\
    \hline
    cuDNN & 8.x \\
    \hline
    IDE & Visual Studio Code \\
    \hline
    \end{tabular}
    \caption{Configuration syst√®me compl√®te}
\end{table}

\chapter{Commandes Utiles}

\section{Installation}

\begin{lstlisting}[language=bash]
# Environment setup
python -m venv wedtect_env
wedtect_env\Scripts\activate

# Install PyTorch with CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install YOLO
pip install ultralytics

# Install all requirements
pip install -r requirements.txt
\end{lstlisting}

\section{Entra√Ænement}

\begin{lstlisting}[language=bash]
# Train model
python train_gpu.py

# Evaluate
python evaluate_and_test.py

# Web scraping
python scrape_google_images.py
\end{lstlisting}

\section{Git Operations}

\begin{lstlisting}[language=bash]
# Push to GitHub
git add .
git commit -m "Update: Model improvements"
git push origin main

# View logs
git log --oneline -5
\end{lstlisting}

\end{document}
